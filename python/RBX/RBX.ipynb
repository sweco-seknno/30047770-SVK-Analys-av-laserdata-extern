{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e66ce073",
   "metadata": {},
   "source": [
    "# RBX\n",
    "## Övergripande arbetsgång\n",
    "    * Importerar punkter från DGN-fil i arbetsmapp till den aktuella databasen.\n",
    "      Hämtar in punkter till databasen och placerar dem under /RBX_clean\n",
    "    * Beräknar avstånd från importerade punkter till fasledningar.\n",
    "      Fasledningar har tidigare hämtats in från Wires.ipynb\n",
    "    * I RBX_polygon.py skapas polygoner, grupperar punkter och hämtar de punkter som har minst avstånd till fas.\n",
    "      Polygoner och punkter skrivs ut till shapefiler (.shp)\n",
    "    * Polygoner och punkter hämtas in till geodatabasen, från shapefilerna, och lägger även till domäner, ledningsgata(nr)\n",
    "      och littera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ab204e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sökvägar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fd61fc2",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_ID': '250128', 'powerline_list': 'Q:/Projekt/Data_2024/styrfiler/veg_kanttrad_250128.txt', 'scandate_file': 'Q:/Projekt/Data_2024/skanningsdatum/skanningsdatum_250128.txt', 'local_folder': 'C:/SVK_2024/pythonkörningar', 'working_gdb_template': 'Q:/Projekt/Data_2024/working_template.gdb', 'results_gdb_template': 'Q:/Projekt/Data_2024/results_template.gdb', 'wires_gdb_template': 'Q:/Projekt/Data_2024/wires_template.gdb', 'dgn_folder': 'Q:/Projekt/Analys_2024/DGN_2024', 'powerlines_folder': 'Q:/Projekt/Analys_2024/ledningar', 'domains_folder': 'Q:/Projekt/Data_2024/Underlag_SVK/Domains', 'LG_polygons': 'Q:/Projekt/Data_2024/Underlag_SVK/Bestallningsunderlag_2024.gdb/GNG_LEDNINGSGATA', 'station_polygons': 'Q:/Projekt/Data_2024/Underlag_SVK/Bestallningsunderlag_2024.gdb/GNG_STATIONSOMRADE'}\n"
     ]
    }
   ],
   "source": [
    "# Läs settings\n",
    "import json\n",
    "import os\n",
    "import arcpy\n",
    "\n",
    "settings_file = r\"Q:\\Projekt\\Data_2024\\styrfiler\\settings_SEKNNO.json\"\n",
    "\n",
    "with open(settings_file, 'r', encoding='utf-8') as file:\n",
    "    settings = json.load(file)\n",
    "\n",
    "print(settings)\n",
    "\n",
    "run_ID = settings[\"run_ID\"]\n",
    "powerline_list = settings[\"powerline_list\"]\n",
    "local_dir = settings[\"local_folder\"]\n",
    "powerlines_folder = settings[\"powerlines_folder\"]\n",
    "domains_folder = settings[\"domains_folder\"]\n",
    "dgn_dir = settings[\"dgn_folder\"]\n",
    "scandate_file = settings[\"scandate_file\"]\n",
    "working_gdb_template = settings[\"working_gdb_template\"]\n",
    "results_gdb_template = settings[\"results_gdb_template\"]\n",
    "cvd_LEDNINGSGATA_path = os.path.join(domains_folder, \"cvd_LEDNINGSGATA.txt\")\n",
    "wires_gdb = os.path.join(local_dir, f\"wires_{run_ID}.gdb\")\n",
    "RBX_shape_folder = os.path.join(local_dir, f\"RBX_shp_{run_ID}\")\n",
    "working_gdb = os.path.join(local_dir, f\"working_{run_ID}.gdb\")\n",
    "results_gdb = os.path.join(local_dir, f\"results_{run_ID}.gdb\")\n",
    "\n",
    "sr = arcpy.SpatialReference(\"SWEREF99_TM\", \"RH2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf2dc594",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/SVK_2024/pythonkörningar\\RBX_shp_250128 finns redan\n",
      "C:/SVK_2024/pythonkörningar\\working_250128.gdb finns redan\n",
      "C:/SVK_2024/pythonkörningar\\results_250128.gdb finns redan\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create empty folder for shapefiles\n",
    "if os.path.exists(RBX_shape_folder):\n",
    "    print(f\"{RBX_shape_folder} finns redan\")\n",
    "else:\n",
    "    os.makedirs(RBX_shape_folder)\n",
    "\n",
    "# Create working gdb as copy of template\n",
    "if os.path.exists(working_gdb):\n",
    "    print(f\"{working_gdb} finns redan\")\n",
    "else: \n",
    "    shutil.copytree(working_gdb_template, working_gdb)\n",
    "\n",
    "# Create results gdb as copy of template\n",
    "if os.path.exists(results_gdb):\n",
    "    print(f\"{results_gdb} finns redan\")\n",
    "else: \n",
    "    shutil.copytree(results_gdb_template, results_gdb)\n",
    "\n",
    "    \n",
    "## Flytta sökvägar till settings-fil\n",
    "#prj_dir = Path(r\"C:\\SVK_2024\\pythonkörningar\")\n",
    "#LGs_info_path = Path(r\"Q:\\Projekt\\Data_2024\\styrfiler\\veg_kanttrad_241217.txt\")\n",
    "#gdb_name = 'veg_kantträd_241217.gdb'\n",
    "#gdb = os.path.join(prj_dir, gdb_name)\n",
    "#wires_gdb = r\"C:\\SVK_2024\\pythonkörningar\\Wires_241217.gdb\"\n",
    "#RBX_polygon_dir = os.path.join(prj_dir, \"RBX_polygons\")\n",
    "#serv_prj_dir = Path(r\"Q:\\Projekt\\Analys_2024\\ledningar\")\n",
    "#dgn_dir = Path(r\"Q:\\Projekt\\Analys_2024\\DGN_2024\")\n",
    "#cvd_LEDNINGSGATA_path = r\"C:\\Users\\SEKNNO\\OneDrive - Sweco AB\\SVK_2024\\30047770-SVK-Analys-av-laserdata-extern\\python\\gdb-mallar-och-domänkoder\\cvd_LEDNINGSGATA.txt\"\n",
    "#cvd_DATE_path = r\"Q:\\Projekt\\Data_2024\\skanningsdatum\\skanningsdatum_241217_temp.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78c5e41",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Slår ihop RBX-filer för blocken till en enda fil för ledningen\n",
    "### Behöver inte köras, den som gör ledningen i TerraScan gör detta själv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc2dada1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#import sys\n",
    "#import glob\n",
    "#import fileinput\n",
    "#import SVK\n",
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339d90c6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Merge RBX txt files for all blocks of a powerline (LGXXX_Y) into one txt\n",
    "#import fileinput\n",
    "#\n",
    "#def merge_blocks(src_dir, search_pattern, dst_file):\n",
    "#    blocks = glob.glob(os.path.join(src_dir, search_pattern))\n",
    "#    with open(dst_file, \"w\") as fh:\n",
    "#        input_lines = fileinput.input(blocks)\n",
    "#        fh.writelines(input_lines)\n",
    "#        \n",
    "#def combine_blocks(row):\n",
    "#    LG = row[\"LG\"]\n",
    "#    line = row[\"line\"]\n",
    "#    line_dir = serv_prj_dir / LG / f\"line_{line}\"\n",
    "#    \n",
    "#    print(f\"Doing {LG}_{line}\")\n",
    "#    block_dir = os.path.join(line_dir, \"RBX\", \"block\")\n",
    "#    combined_blocks_path = os.path.join(line_dir, \"RBX\", \"RBX_raw.txt\")\n",
    "#    merge_blocks(block_dir, \"*_pt*.txt\", combined_blocks_path)\n",
    "#\n",
    "#LGs_info = pd.read_csv(LGs_info_path, sep=\"\\t\", header=0)\n",
    "#print(LGs_info)\n",
    "#LGs_info.apply(combine_blocks, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb750995",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Denna kopierar över alla rbx_raw.txt till den temporära mappen på skrivbordet\n",
    "### Är det nödvändigt? Jag tror att det som gör skillnad för hastigheten är om gdb:er / shapefiler ligger lokalt istället för på server. /Karin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d340cb6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#import filecmp\n",
    "#import shutil\n",
    "#import pandas as pd\n",
    "#df = pd.DataFrame()\n",
    "#to_dir = os.path.join(prj_dir, \"ledningar\")\n",
    "#from_dir = serv_prj_dir\n",
    "#\n",
    "##LGs_info_path = os.path.join(prj_dir, LGs_info_name)\n",
    "#\n",
    "#LGs_info = pd.read_csv(LGs_info_path, sep=\"\\t\", header=0)\n",
    "#testlist = []\n",
    "#for i, j in zip(LGs_info[\"LG\"], LGs_info[\"line\"]):\n",
    "#    testlist.append(f'{i}\\\\line_{j}\\\\RBX')\n",
    "#\n",
    "## print(testlist)\n",
    "#outlist_to_dir = []\n",
    "#for i in testlist:\n",
    "#    outlist_to_dir.append((f\"{to_dir}\\{i}\\RBX_raw.txt\").replace('\\\\\\\\', '\\\\'))\n",
    "#\n",
    "#outlist_from_dir = []\n",
    "#for i in testlist:\n",
    "#    outlist_from_dir.append(\n",
    "#        (f\"{from_dir}\\{i}\\RBX_raw.txt\").replace('\\\\\\\\', '\\\\'))\n",
    "#\n",
    "#for i, j in zip(outlist_from_dir, outlist_to_dir):\n",
    "#    if os.path.exists(j.replace('\\\\\\\\', '\\\\')):\n",
    "#        shutil.copyfile(i.replace('\\\\\\\\', '\\\\'), j.replace('\\\\\\\\', '\\\\'))\n",
    "#    else:\n",
    "#        folder1 = j.split(\"\\\\\")[-4]\n",
    "#        folder2 = j.split(\"\\\\\")[-3]\n",
    "#        folder3 = j.split(\"\\\\\")[-2]\n",
    "#        os.makedirs(\n",
    "#            os.path.join(\n",
    "#                to_dir,\n",
    "#                folder1,\n",
    "#                folder2,\n",
    "#                folder3\n",
    "#            )\n",
    "#        )\n",
    "#        shutil.copyfile(i.replace('\\\\\\\\', '\\\\'), j.replace('\\\\\\\\', '\\\\'))\n",
    "#\n",
    "#for i, j in zip(outlist_from_dir, outlist_to_dir):\n",
    "#    print(filecmp.cmp(i, j))\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c7afcf",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Importera rensade RBX från dgn till gdb\n",
    "Hämtar in punkter från DGN-filer till geodatabasen. <br>\n",
    "DGN-filerna ska finnas som undermapp i projektmappen. <br>\n",
    "Punkter som hämtas ska ligga i lager 20 i DGN-filerna.<br>\n",
    "Om punkter ligger i annat lager kommer inga punkter att importeras. <br>\n",
    "Ledningsgator och ledningar som behandlas utfrån från textfil där alla ledningar som ska köras finns med. <br>\n",
    "Textfilen importeras och görs till en dataframe. <br>\n",
    "I geodatabasen kommer punkterna placeras under clean_RBX_points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5436388",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "påbörjar LG022_1\n",
      "Q:/Projekt/Analys_2024/DGN_2024\\LG022_1.dgn\n",
      "vTab merged to output_fc\n",
      "Layer deleted\n",
      "påbörjar LG022_2\n",
      "Q:/Projekt/Analys_2024/DGN_2024\\LG022_2.dgn\n",
      "vTab merged to output_fc\n",
      "Layer deleted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy RBX from dgn to working_gdb feature class, one fc for each LGXXX_Y\n",
    "import arcpy, os, glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "output_fd = os.path.join(working_gdb, \"clean_RBX_points\")\n",
    "\n",
    "def dgn_to_gdb(powerline): \n",
    "    LG = powerline[\"LG\"]\n",
    "    line = powerline[\"line\"]\n",
    "    littera = powerline[\"Littera\"]\n",
    "    \n",
    "    os.chdir(dgn_dir)\n",
    "    \n",
    "    print(f\"påbörjar {LG}_{line}\")\n",
    "    arcpy.env.overwriteOutput = True\n",
    "    dgn = os.path.join(dgn_dir, LG+\"_\"+str(line)+\".dgn\") #\n",
    "    print(dgn)\n",
    "\n",
    "    output_fc = os.path.join(output_fd, LG+\"_\"+str(line)+\"_RBX_clean\") #var punkterna ska exporteras till\n",
    "\n",
    "    #print(os.path.join(output_fd, LG+\"_\"+str(line)+\"_RBX_clean\"))\n",
    "    # Create a value table that will hold the input feature classes for Merge\n",
    "    vTab = arcpy.ValueTable()\n",
    "    #print(\"vTab created\")\n",
    "    layername_RBX = dgn + '_Layer_LVL20'\n",
    "    arcpy.MakeFeatureLayer_management(dgn + '/Point', layername_RBX, \"\\\"Level\\\" = 20\")\n",
    "    #print(\"MakeFeatureLayer complete\")\n",
    "    vTab.addRow([layername_RBX, 2])\n",
    "    #print(\"Row added to vTab\")\n",
    "\n",
    "    # Merge the CAD features into one feature class\n",
    "    arcpy.env.workspace = output_fd\n",
    "    arcpy.Merge_management(vTab, output_fc)\n",
    "    print(\"vTab merged to output_fc\")\n",
    "    \n",
    "    # ta bort fält som inte ska användas\n",
    "    keep_fields = [\"Shape\", \"OBJECTID\"]\n",
    "    all_fields = arcpy.ListFields(output_fc)\n",
    "    fields_to_delete = [field.name for field in all_fields if field.name not in keep_fields]\n",
    "    if fields_to_delete:\n",
    "        arcpy.DeleteField_management(output_fc, fields_to_delete)\n",
    "\n",
    "    arcpy.Delete_management(layername_RBX)\n",
    "    print(\"Layer deleted\")\n",
    "\n",
    "    #arcpy.env.workspace = dgn_dir\n",
    " \n",
    "powerlines_df = pd.read_csv(powerline_list, sep=\"\\t\", header=0)\n",
    "powerlines_df.apply(dgn_to_gdb, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62544671",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Near 3D - avstånd till fas för RBX\n",
    "Beräknar avstånd från importerade punkter till aktuell ledning med hjälp av \"Near3D_3d\". <br>\n",
    "Lägger till avstånd till punkterna i nya fält \"AVSTAND_FAS\" och \"AVSTAND_HORISONTELLT\" för respektive punkt. <br>\n",
    "Skriptet utgår från tidigare nämnda textfil för vilka ledningsgator som ska behandlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d14f915",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LG022_1, littera UL7 S5-6\n",
      "done with Near3D LG022_1_RBX_clean\n",
      "done with delete and alter field LG022_1_RBX_clean\n",
      "Distance to wire computed for RBX LG022_1\n",
      "LG022_2, littera UL7 S2-4\n",
      "done with Near3D LG022_2_RBX_clean\n",
      "done with delete and alter field LG022_2_RBX_clean\n",
      "Distance to wire computed for RBX LG022_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcpy, os, glob\n",
    "arcpy.CheckOutExtension('3D')\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "fd_RBX = os.path.join(working_gdb, 'clean_RBX_points')\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "def dist2wire(fd_RBX, fc_name_RBX, fc_wires, radius):\n",
    "    # Compute distance from RBX point to wire\n",
    "    fc_RBX = os.path.join(fd_RBX, fc_name_RBX)\n",
    "    arcpy.Near3D_3d(in_features=fc_RBX, near_features=fc_wires, search_radius=radius, location=\"NO_LOCATION\", angle=\"NO_ANGLE\", delta=\"NO_DELTA\")\n",
    "    print('done with Near3D '+fc_name_RBX)\n",
    "    arcpy.DeleteField_management(in_table=fc_RBX, drop_field=\"NEAR_FID\")\n",
    "    arcpy.management.AlterField(in_table=fc_RBX, field=\"NEAR_DIST3\", new_field_name=\"AVST_F\")\n",
    "    arcpy.management.AlterField(in_table=fc_RBX, field=\"NEAR_DIST\", new_field_name=\"AVST_H\")\n",
    "    print('done with delete and alter field '+fc_name_RBX)\n",
    "    \n",
    "    \n",
    "def RBX_3D_distance(powerline):\n",
    "    LG = powerline[\"LG\"]\n",
    "    line = powerline[\"line\"]\n",
    "    littera = powerline[\"Littera\"]\n",
    "    \n",
    "    print(f\"{LG}_{line}, littera {littera}\")\n",
    "    \n",
    "    fc_name_RBX = f\"{LG}_{line}_RBX_clean\"\n",
    "    fc_name_wires = f\"{LG}_{line}_fas\"\n",
    "    fc_wires = os.path.join(wires_gdb, fc_name_wires)\n",
    "    \n",
    "    if arcpy.Exists(os.path.join(fd_RBX, fc_name_RBX)):\n",
    "        dist2wire(fd_RBX, fc_name_RBX, fc_wires, 6)\n",
    "        print(f\"Distance to wire computed for RBX {LG}_{line}\")\n",
    "    else:\n",
    "        print(f\"{os.path.join(fd_RBX, fc_name_RBX)} does not exist\")\n",
    "\n",
    "# The file pointed at by LGs_info_path contains only the powerlines that should be\n",
    "# processed. So this file has to be updated each time we want to process a new set of\n",
    "# powerlines. This is unpractical - consider a user prompt where the user can select\n",
    "# which powerlines to process\n",
    "\n",
    "powerlines_df = pd.read_csv(powerline_list, sep=\"\\t\", header=0)\n",
    "powerlines_df.apply(RBX_3D_distance, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd80cad",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Skapa fält för littera mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749f538",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#def add_fields(powerline):\n",
    "#    LG = powerline[\"LG\"]\n",
    "#    line = powerline[\"line\"]\n",
    "#    littera = powerline[\"Littera\"]\n",
    "#    \n",
    "#    print(f\"{LG}_{line}, littera {littera}\")\n",
    "#    \n",
    "#    fc_name_RBX = f\"{LG}_{line}_RBX_clean\"\n",
    "#\n",
    "#    if arcpy.Exists(os.path.join(fd_RBX, fc_name_RBX)):\n",
    "#        \n",
    "#        print(f\"Fields added to RBX {LG}_{line}\")\n",
    "#    else:\n",
    "#        print(f\"{os.path.join(fd_RBX, fc_name_RBX)} does not exist\")\n",
    "#    \n",
    "#\n",
    "#powerlines_df = pd.read_csv(powerline_list, sep=\"\\t\", header=0)\n",
    "#powerlines_df.apply(add_fields axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbafa93",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#  gör shp med polygoner, alla punkter, närmaste punkter\n",
    "delar in punkter och polygoner i farlighetsklass\n",
    "sätter minsta avstånd till fas för varje polygon. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f17f3b6e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing LG022_1\n",
      "Clustered_buffers:                                             geometry\n",
      "0  POLYGON ((609487.122 7018323.139, 609487.101 7...\n",
      "Clustered_buffers:                                             geometry\n",
      "0  POLYGON ((609045.417 7016873.003, 609045.384 7...\n",
      "1  POLYGON ((609046.074 7016878.547, 609046.037 7...\n",
      "2  POLYGON ((609362.234 7018035.937, 609362.197 7...\n",
      "Nr of points: 243\n",
      "Nr of polygons: 12\n",
      "   polygon_ID AVSTAND_FAS    AVST_H    dz    AVST_F  index_right\n",
      "0           0              0.436731  4.43  5.444561            0\n",
      "1           1              0.668028  4.93  5.299389            1\n",
      "2           2              1.477024  5.75  4.514675            2\n",
      "3           3              1.779039  4.59  4.721544            3\n",
      "4           4              1.709682  4.81  4.376525            4\n",
      "Number of closest points: 12\n",
      "Original polygon columns: Index(['geometry', 'LG', 'littera', 'polygon_ID'], dtype='object')\n",
      "Merged polygon columns: Index(['geometry', 'LG', 'littera', 'polygon_ID', 'AVSTAND_FAS', 'AVST_H',\n",
      "       'dz', 'AVST_F', 'index_right'],\n",
      "      dtype='object')\n",
      "Columns: Index(['LG', 'littera', 'AVST_F', 'AVST_H', 'geometry', 'dz'], dtype='object')\n",
      "Nr of points: 5\n",
      "Nr of polygons: 1\n",
      "   polygon_ID AVSTAND_FAS    AVST_H    dz    AVST_F  index_right\n",
      "0           0              1.040077  5.12  3.914155            0\n",
      "Number of closest points: 1\n",
      "Original polygon columns: Index(['geometry', 'LG', 'littera', 'polygon_ID'], dtype='object')\n",
      "Merged polygon columns: Index(['geometry', 'LG', 'littera', 'polygon_ID', 'AVSTAND_FAS', 'AVST_H',\n",
      "       'dz', 'AVST_F', 'index_right'],\n",
      "      dtype='object')\n",
      "Columns: Index(['LG', 'littera', 'AVST_F', 'AVST_H', 'geometry', 'dz'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11]:370: FutureWarning: You are adding a column named 'geometry' to a GeoDataFrame constructed without an active geometry column. Currently, this automatically sets the active geometry column to 'geometry' but in the future that will no longer happen. Instead, either provide geometry to the GeoDataFrame constructor (GeoDataFrame(... geometry=GeoSeries()) or use `set_geometry('geometry')` to explicitly set the active geometry column.\n",
      "[11]:370: FutureWarning: You are adding a column named 'geometry' to a GeoDataFrame constructed without an active geometry column. Currently, this automatically sets the active geometry column to 'geometry' but in the future that will no longer happen. Instead, either provide geometry to the GeoDataFrame constructor (GeoDataFrame(... geometry=GeoSeries()) or use `set_geometry('geometry')` to explicitly set the active geometry column.\n",
      "[11]:370: FutureWarning: You are adding a column named 'geometry' to a GeoDataFrame constructed without an active geometry column. Currently, this automatically sets the active geometry column to 'geometry' but in the future that will no longer happen. Instead, either provide geometry to the GeoDataFrame constructor (GeoDataFrame(... geometry=GeoSeries()) or use `set_geometry('geometry')` to explicitly set the active geometry column.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing LG022_2\n",
      "Clustered_buffers:                                             geometry\n",
      "0  POLYGON ((650681.698 7089559.581, 650681.69 70...\n",
      "1  POLYGON ((650670.19 7089559.703, 650670.179 70...\n",
      "2  POLYGON ((650693.23 7089586.513, 650693.219 70...\n",
      "Nr of points: 3\n",
      "Nr of polygons: 3\n",
      "   polygon_ID AVSTAND_FAS    AVST_H    dz    AVST_F  index_right\n",
      "0           0              0.889036  4.25  5.388875            0\n",
      "1           1              0.443775  4.89  5.376464            1\n",
      "2           2              0.630216  3.51  5.428878            2\n",
      "Number of closest points: 3\n",
      "Original polygon columns: Index(['geometry', 'LG', 'littera', 'polygon_ID'], dtype='object')\n",
      "Merged polygon columns: Index(['geometry', 'LG', 'littera', 'polygon_ID', 'AVSTAND_FAS', 'AVST_H',\n",
      "       'dz', 'AVST_F', 'index_right'],\n",
      "      dtype='object')\n",
      "Columns: Index(['LG', 'littera', 'AVST_F', 'AVST_H', 'geometry', 'dz'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11]:370: FutureWarning: You are adding a column named 'geometry' to a GeoDataFrame constructed without an active geometry column. Currently, this automatically sets the active geometry column to 'geometry' but in the future that will no longer happen. Instead, either provide geometry to the GeoDataFrame constructor (GeoDataFrame(... geometry=GeoSeries()) or use `set_geometry('geometry')` to explicitly set the active geometry column.\n",
      "[11]:370: FutureWarning: You are adding a column named 'geometry' to a GeoDataFrame constructed without an active geometry column. Currently, this automatically sets the active geometry column to 'geometry' but in the future that will no longer happen. Instead, either provide geometry to the GeoDataFrame constructor (GeoDataFrame(... geometry=GeoSeries()) or use `set_geometry('geometry')` to explicitly set the active geometry column.\n",
      "[11]:370: FutureWarning: You are adding a column named 'geometry' to a GeoDataFrame constructed without an active geometry column. Currently, this automatically sets the active geometry column to 'geometry' but in the future that will no longer happen. Instead, either provide geometry to the GeoDataFrame constructor (GeoDataFrame(... geometry=GeoSeries()) or use `set_geometry('geometry')` to explicitly set the active geometry column.\n"
     ]
    }
   ],
   "source": [
    "8# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Aug 16 16:16:11 2021\n",
    "\n",
    "@author: SEKNNO\n",
    "\"\"\"\n",
    "# %% imports\n",
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import copy\n",
    "from fiona import supported_drivers\n",
    "from geopandas.tools import sjoin\n",
    "from geopandas.tools import overlay\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import unary_union\n",
    "import numpy\n",
    "\n",
    "\n",
    "# %% FUNCTIONS\n",
    "# FUNCTIONS\n",
    "def create_dir(dir_path):\n",
    "    \"\"\"Creating directory\n",
    "\n",
    "    Given the path, the functions creates a directory\n",
    "    if there is none.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(dir_path + \" created.\")\n",
    "    else:\n",
    "        print(dir_path + \" already exists. Not overwritten.\")\n",
    "\n",
    "\n",
    "def buffer_points(points):\n",
    "    \"\"\"Buffering points.\n",
    "\n",
    "    For the given points,\n",
    "    the function creates a specified sized buffer for these.\n",
    "    \"\"\"\n",
    "    buffer_geom = points.geometry.buffer(0.5, cap_style=1)\n",
    "    buffered_points = gpd.GeoDataFrame(geometry=buffer_geom)\n",
    "    return (buffered_points)\n",
    "\n",
    "\n",
    "def cluster_buffers(buffers):\n",
    "    \"\"\"Clustering buffer objects.\n",
    "\n",
    "    Given the buffered points, the function creates clusters\n",
    "    which are used to group points and later create polygons.\n",
    "    \"\"\"\n",
    "    # Creating GeoSeries with unions of buffered points.\n",
    "    buffers_union = gpd.GeoSeries(unary_union(buffers.geometry))\n",
    "    # Exploding the unions in a new GeoDataFrame.\n",
    "    clustered_buffers = buffers_union.explode(index_parts=False)\n",
    "    clustered_buffers = gpd.GeoDataFrame(geometry=clustered_buffers)\n",
    "    # Resetting indices\n",
    "    clustered_buffers.reset_index(drop=True, inplace=True)\n",
    "    # Sorting out geometry columns\n",
    "    #clustered_buffers.geometry = clustered_buffers.iloc[:, 2]\n",
    "    #clustered_buffers = clustered_buffers[[\"geometry\"]]\n",
    "    print(f\"Clustered_buffers: {clustered_buffers.head(3)}\")\n",
    "    # Setting coordinate system for GeoDataFrame\n",
    "    clustered_buffers.set_crs(\"epsg:3006\", inplace=True)\n",
    "    # Returning cluster GDF.\n",
    "    return (clustered_buffers)\n",
    "\n",
    "\n",
    "def read_points(gdb, LG, line):\n",
    "    \"\"\"Reading information from file.\n",
    "\n",
    "    Import points from gdb (which have had false alarms removed\n",
    "    manually in MicroStation and then exported to gdb\n",
    "    and Near3D (avst fas) computed)\n",
    "    \"\"\"\n",
    "    # Defining layer name based on line number.\n",
    "    point_layer = f\"{LG}_{line}_RBX_clean\"\n",
    "    # Checking if layer name is relevant.\n",
    "    if point_layer not in RBX_gdb_layers:\n",
    "        # no points from which to make clusters: return nothing.\n",
    "        return ([], [])\n",
    "    # Reading file.\n",
    "    points = gpd.read_file(gdb, layer=point_layer)\n",
    "    # Creating new list with relevant coulmn.\n",
    "    #points = points[[\"AVSTAND_FAS\", \"AVSTAND_HORISONTELLT\", \"geometry\"]] ###### ÄNDRAT 2025-01-14 ######\n",
    "    points = points[[\"AVST_F\", \"AVST_H\", \"geometry\"]] ###### ÄNDRAT 2025-01-14 ######\n",
    "    # Checking if lists are containing any columns.\n",
    "    if len(points) == 0:\n",
    "        # If empty, return empty list.\n",
    "        return ([], [])\n",
    "    # Returning points list.\n",
    "    return (points)\n",
    "\n",
    "\n",
    "def read_raw_RBX(raw_RBX_file):\n",
    "    \"\"\"Reading infomation from file\n",
    "\n",
    "    Used to get the dz, the height, for points,\n",
    "    which is not contained in the dgn-file.\n",
    "    Reading the RAW RBX file and then adding the calculated value to \n",
    "    the actual point.\n",
    "    \"\"\"\n",
    "    # Reading file\n",
    "    raw_RBX = pd.read_csv(raw_RBX_file, header=None,\n",
    "                          sep=\" \", names=[\"x\", \"y\", \"z\", \"dz\"])\n",
    "    # Creating GeoDataFrame from the imported list and calculating\n",
    "    # the dz value.\n",
    "    raw_RBX_points = gpd.GeoDataFrame(\n",
    "        raw_RBX, geometry=gpd.points_from_xy(\n",
    "            raw_RBX.x, raw_RBX.y, (raw_RBX.z - raw_RBX.dz)))\n",
    "    # Dropping the irrelevant information.\n",
    "    raw_RBX_points.drop([\"x\", \"y\"], axis=1, inplace=True)\n",
    "    # Returning the extended GDF with the dz value.\n",
    "    return (raw_RBX_points)\n",
    "\n",
    "\n",
    "def make_RBX_polygons(points, voltage, LG, littera, RBX_class):\n",
    "    \"\"\"Create polygons from the RBX points.\n",
    "\n",
    "    Get max 3D distance from wire for RBX_class\n",
    "    \"\"\"\n",
    "    RBX_dist = RBX_distances[voltage][RBX_class]\n",
    "    # extract points within RBX_dist\n",
    "    # RBX_class_points = points[points[\"AVSTAND_FAS\"] <= RBX_dist] #### ÄNDRAT 2025-01-14\n",
    "    RBX_class_points = points[points[\"AVST_F\"] <= RBX_dist]\n",
    "    if len(RBX_class_points) == 0:\n",
    "        return ([], [])\n",
    "    # buffer points, create clusters\n",
    "    buffers = buffer_points(RBX_class_points)\n",
    "    clusters = cluster_buffers(buffers)\n",
    "    clusters['LG'] = LG\n",
    "    clusters['littera'] = littera\n",
    "\n",
    "    return (clusters, RBX_class_points)\n",
    "\n",
    "\n",
    "def set_class(points, voltage, LG, littera, RBX_class, RBX_class_nr):\n",
    "    \"\"\"Set \"KLASS_TEMP\" value for points.\n",
    "\n",
    "    Setting value based on distance to line, type of voltage and RBX class.\n",
    "    \"\"\"\n",
    "    # Deciding which distance is to be calculated\n",
    "    RBX_dist = RBX_distances[voltage][RBX_class]\n",
    "    # Filtering out points whos distance is less than the acceptable.\n",
    "    # RBX_class_points = points[points[\"AVSTAND_FAS\"] <= RBX_dist] #### ÄNDRAT 2025-01-14\n",
    "    RBX_class_points = points[points[\"AVST_F\"] <= RBX_dist]\n",
    "    # Filtering out points whos distance is not less than the acceptable.\n",
    "    # Not edited.\n",
    "    # RBX_no_class_points = points[points[\"AVSTAND_FAS\"] > RBX_dist] #### ÄNDRAT 2025-01-14\n",
    "    RBX_no_class_points = points[points[\"AVST_F\"] > RBX_dist]\n",
    "    # Set the value of class for the relevant points.\n",
    "    RBX_class_points[\"KLASS_TEMP\"] = RBX_class_nr\n",
    "\n",
    "    # Returning the the full points list, where some points has been changed.\n",
    "    return (RBX_class_points._append(RBX_no_class_points))\n",
    "\n",
    "\n",
    "def clip_polygons(clippee, clipper):\n",
    "    \"\"\"Clip overlay polygons.\n",
    "\n",
    "    Using the higher class polygon as template,\n",
    "    the function makes a cut in the lower class polygon\n",
    "    so that no overlap exist.\n",
    "    \"\"\"\n",
    "    # Check if the there is a lower class polygon.\n",
    "    # If not, the returning empty list.\n",
    "    if len(clippee) == 0:\n",
    "        return ([], [])\n",
    "    # Check if there is a higher class polygon,\n",
    "    # if not, then returning the lower class polygon unclipped.\n",
    "    if len(clipper) == 0:\n",
    "        return clippee\n",
    "    # Clipping the the higher class polygon out of the lower class polygon.\n",
    "    clipped = overlay(clippee, clipper, how=\"difference\")\n",
    "    # Returning the clipped lower class polygon\n",
    "    return clipped\n",
    "\n",
    "\n",
    "def calculate_RBX_area(RBX):\n",
    "    \"\"\"Calculating the area for polygons.\"\"\"\n",
    "    # Check if the there is a polygon.\n",
    "    # If not, the returning empty list.\n",
    "    if len(RBX) == 0:\n",
    "        return 0\n",
    "    # Calculating area\n",
    "    area = RBX.geometry.area.sum()\n",
    "    return area\n",
    "\n",
    "\n",
    "def get_attributes_from_points(polygons, points):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    if str(type(polygons)) != \"<class 'geopandas.geodataframe.GeoDataFrame'>\":\n",
    "        return ([], [])\n",
    "    polygons[\"polygon_ID\"] = polygons.index\n",
    "    print(f\"Nr of points: {len(points)}\")\n",
    "    print(f\"Nr of polygons: {len(polygons)}\")\n",
    "\n",
    "    points_with_ID = sjoin(points, polygons, how=\"inner\")\n",
    "    # sorted_points = points_with_ID.sort_values(by='AVSTAND_FAS') #### ÄNDRAT 2025-01-14\n",
    "    sorted_points = points_with_ID.sort_values(by='AVST_F')\n",
    "    closest_points = sorted_points.groupby('polygon_ID').first().reset_index()\n",
    "    closest_points_full = copy.deepcopy(closest_points)\n",
    "    # inplace för att ändra den faktiska punkten\n",
    "    closest_points.drop([\"geometry\", \"LG\", \"littera\"], axis=1, inplace=True)\n",
    "    print(closest_points[0:5])\n",
    "    print(f\"Number of closest points: {len(closest_points)}\")\n",
    "\n",
    "    # kopplar på information till polygon från closest point\n",
    "    # tillfällig\n",
    "    polys_ = polygons.merge(closest_points, on=\"polygon_ID\")\n",
    "    print(f\"Original polygon columns: {polygons.columns}\")\n",
    "    print(f\"Merged polygon columns: {polys_.columns}\")\n",
    "\n",
    "    # kolla koppling mellan denna och poly_\n",
    "    #polys = polys_[[\"LG\", \"littera\", \"AVSTAND_FAS\",\n",
    "    #                \"AVSTAND_HORISONTELLT\", \"geometry\", \"dz\"]] #### ÄNDRAT 2025-01-14\n",
    "    polys = polys_[[\"LG\", \"littera\", \"AVST_F\",\n",
    "                    \"AVST_H\", \"geometry\", \"dz\"]]\n",
    "    print(f\"Columns: {polys.columns}\")\n",
    "\n",
    "    return (polys, closest_points_full)\n",
    "\n",
    "\n",
    "def set_z_to_points(points, raw_rbx_file):\n",
    "    \"\"\"Setting ground level z to clean points\n",
    "\n",
    "    Z value is changed from the original \\\\\n",
    "    z value (z + dz value of the clean point) \\\\\n",
    "    to the z value from the same raw_rbx point (z - dz, ground level)\n",
    "\n",
    "    Keyword arguments: \\\\\n",
    "    points -- dataframe of verified rbx points \\\\\n",
    "    raw_rbx -- dataframe of all rbx points \\\\\n",
    "    raw_rbx_file -- text document containing information about the raw points\n",
    "\n",
    "    out : dataframe(\n",
    "        AVSTAND_FAS, \\\\\n",
    "        AVSTAND_HORISONTELLT, \\\\\n",
    "        geometry(x, y, z(ground level))\n",
    "    )\n",
    "    \"\"\"\n",
    "    # Checking if the input data is as GeoDataFrame\n",
    "    # If not, returning empty list\n",
    "    if str(type(points)) != \"<class 'geopandas.geodataframe.GeoDataFrame'>\":\n",
    "        return ([], [])\n",
    "    raw_rbx = pd.read_csv(raw_rbx_file, header=None,\n",
    "                          sep=\" \", names=[\"x\", \"y\", \"z\",\n",
    "                                          \"dz\", \"LG\", \"littera\"]\n",
    "                          )\n",
    "\n",
    "    # adding columns to points dataframe for x, y values.\n",
    "    points[\"x\"] = points.centroid.map(lambda p: p.x)\n",
    "    points[\"y\"] = points.centroid.map(lambda p: p.y)\n",
    "\n",
    "    # creating container for numeric x, y, z values.\n",
    "\n",
    "    # 2023-02-06\n",
    "    points[\"dz\"] = numpy.float64\n",
    "\n",
    "    pointlst = []\n",
    "    point_lst_dz = []\n",
    "    no_ref_points = []\n",
    "    # for each point in sorted db, getting the index for further comparison\n",
    "    for ind1 in range(0, len(points)):\n",
    "        checklst = []\n",
    "        # for each point in the raw_rbx db,\n",
    "        # getting the index for further comparison\n",
    "        for ind2 in range(0, len(raw_rbx)):\n",
    "            # validating if the x values and the y values are the same\n",
    "            # for the clean_point and raw_point resp.\n",
    "            if (round(points.x[ind1], 2) == raw_rbx.x[ind2]\n",
    "                    and round(points.y[ind1], 2) == raw_rbx.y[ind2]):\n",
    "                # if statement is true,\n",
    "                # then the points are the same in x, y direction,\n",
    "                # which means the z value can be changed\n",
    "                # from dz (sorted point)\n",
    "                # to z (raw_rbx_point, ground level).\n",
    "                pointlst.append(\n",
    "                    [\n",
    "                        \"\", \"\", points.x[ind1], points.y[ind1],\n",
    "                        round((raw_rbx.z[ind2] - raw_rbx.dz[ind2]), 1),\n",
    "                        raw_rbx.dz[ind2]\n",
    "                    ]\n",
    "                )\n",
    "                point_lst_dz.append(raw_rbx.dz[ind2])\n",
    "                checklst.append(raw_rbx.dz[ind2])\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        # 2023-02-06\n",
    "        if not checklst:\n",
    "            no_ref_points.append(points.iloc[ind1])\n",
    "        # 2022\n",
    "        # else:\n",
    "        #    continue\n",
    "    # creating a dataframe, setting headers.\n",
    "    #pointlst_df = pd.DataFrame(\n",
    "    #    pointlst, columns=[\n",
    "    #        \"AVSTAND_FAS\", \"AVSTAND_HORISONTELLT\",\n",
    "    #        \"x\", \"y\", \"z\", \"dz\"]) ###### ÄNDRAT 2025-01-14\n",
    "    pointlst_df = pd.DataFrame(\n",
    "        pointlst, columns=[\n",
    "            \"AVSTAND_FAS\", \"AVST_H\",\n",
    "            \"x\", \"y\", \"z\", \"dz\"])    \n",
    "\n",
    "    # creating points from the numeric values in the dataframe.\n",
    "    newpointlst = gpd.GeoDataFrame(pointlst_df, geometry=gpd.points_from_xy(\n",
    "        pointlst_df[\"x\"], pointlst_df[\"y\"], pointlst_df[\"z\"]), crs=\"epsg:3006\"\n",
    "    )\n",
    "    # checking that the length of points list (list in)\n",
    "    # is equal to the length of the generated list (list out)\n",
    "    if len(newpointlst) != len(points):\n",
    "        return None\n",
    "\n",
    "    # adding the old information to the new dataframe.\n",
    "    #newpointlst[\"AVSTAND_FAS\"] = points[\"AVSTAND_FAS\"]\n",
    "    #newpointlst[\"AVSTAND_HORISONTELLT\"] = points[\"AVSTAND_HORISONTELLT\"] #### ÄNDRAT 2025-01-14\n",
    "    newpointlst[\"AVST_F\"] = points[\"AVST_F\"]\n",
    "    newpointlst[\"AVST_H\"] = points[\"AVST_H\"]\n",
    "\n",
    "    \n",
    "    # removing the columns for the numeric x, y, z values\n",
    "    newpointlst.drop([\"x\", \"y\", \"z\"], axis=1, inplace=True)\n",
    "\n",
    "    # returning the new dataframe\n",
    "    return newpointlst\n",
    "\n",
    "\n",
    "def round_values(gdf):\n",
    "    \"\"\"Rounding up values.\n",
    "\n",
    "    When getting a GeoDataFrame,\n",
    "    the funtion is rounding the value up to one decimal\n",
    "    for the \"AVSTAND_FAS\" and \"AVSTAND_HORISONTELLT\"\n",
    "    \"\"\"\n",
    "    # Sorting out the relevant columns\n",
    "    #rndvals = ['AVSTAND_FAS', 'AVSTAND_HORISONTELLT', 'dz'] ##### ÄNDRAT 2025-01-14\n",
    "    rndvals = ['AVST_F', 'AVST_H', 'dz']\n",
    "    columns = gdf.columns\n",
    "    # Rounding up the value per column\n",
    "    for col in rndvals:\n",
    "        if col in columns:\n",
    "            gdf[col] = round(gdf[col], 1)\n",
    "    # Returning updated GeoDataFrame\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def sort_columns(gdf):\n",
    "    \"\"\"Sorting GeoDataFrame for consistency\n",
    "\n",
    "    Given the output GeoDataFrame,\n",
    "    the function sorts the relevant columns in right order.\n",
    "    \"\"\"\n",
    "    # Creating list of how the GDF is going to be sorted\n",
    "#    order = ['geometry', 'AVSTAND_FAS', 'AVSTAND_HORISONTELLT',\n",
    "#             'dz', 'LG', \"littera\", 'KLASS_TEMP'] #### ÄNDRAT 2025-01-14\n",
    "    order = ['geometry', 'AVST_F', 'AVST_H',\n",
    "             'dz', 'LG', \"littera\", 'KLASS_TEMP']\n",
    "    # Creating empty GDF\n",
    "    out_gdf = gpd.GeoDataFrame()\n",
    "    # Get all columns\n",
    "    columns = gdf.columns\n",
    "    # Sorting per column\n",
    "    for col in order:\n",
    "        if col in columns:\n",
    "            out_gdf[col] = gdf[col]\n",
    "    # Return sorted GDF\n",
    "    return out_gdf\n",
    "\n",
    "\n",
    "def RBX_polys_stats(row):\n",
    "    \"\"\"Main function of RBX_polygons.py\"\"\"\n",
    "\n",
    "    # Fecthing values, row by row, from the line dataframe.\n",
    "    LG = row[\"LG\"]\n",
    "    line = row[\"line\"]\n",
    "    littera = row[\"Littera\"]\n",
    "    voltage = row[\"Spänning\"]\n",
    "\n",
    "    # Prompting which line is handled\n",
    "    print(f\"Doing {LG}_{line}\")\n",
    "\n",
    "    # the cleaned RBX points that where imported from dgn to gdb\n",
    "    points = read_points(working_gdb, LG, line)\n",
    "    if str(type(points)) != \"<class 'geopandas.geodataframe.GeoDataFrame'>\":\n",
    "        print(\"No points in list\")\n",
    "        return ([], [])\n",
    "\n",
    "    # the raw RBX points from the txt file.\n",
    "    # Needed because they have dZ attribute\n",
    "    raw_RBX_file = os.path.join(\n",
    "        powerlines_folder, LG,\n",
    "        f\"line_{line}\", \"RBX\", str(\"RBX_raw.txt\"))\n",
    "\n",
    "    # Using \"set_z_points\" function to add z value to all points.\n",
    "    points = set_z_to_points(points, raw_RBX_file)\n",
    "\n",
    "    # Creating polygons from distance to line.\n",
    "    if len(points) > 0:\n",
    "        red_polygons, red_points = make_RBX_polygons(\n",
    "            points, voltage, LG, littera, \"red\")\n",
    "        orange_polygons, orange_points = make_RBX_polygons(\n",
    "            points, voltage, LG, littera, \"orange\")\n",
    "        yellow_polygons, yellow_points = make_RBX_polygons(\n",
    "            points, voltage, LG, littera, \"yellow\")\n",
    "\n",
    "    # Creating a default value and column for \"KLASS_TEMP\".\n",
    "    points[\"KLASS_TEMP\"] = 0\n",
    "    # Using the \"set_class\" function for setting relevant \"KLASS_TEMP\" value\n",
    "    # for all points.\n",
    "    if len(points) > 0:\n",
    "        points = set_class(\n",
    "            points, voltage, LG, littera, \"yellow\", 1)\n",
    "        points = set_class(\n",
    "            points, voltage, LG, littera, \"orange\", 2)\n",
    "        points = set_class(\n",
    "            points, voltage, LG, littera, \"red\", 3)\n",
    "\n",
    "    # Getting all the closest points from the unclipped yellow polygons.\n",
    "    # The unclipped yellow polygons are used to cluster all points in groups,\n",
    "    # sort them as descending by \"AVSTAND_FAS\" and get the point with smallest\n",
    "    # distance for each group.\n",
    "    yellow_polygons[\"polygon_ID\"] = yellow_polygons.index\n",
    "    closest_points = sjoin(yellow_points, yellow_polygons, how=\"inner\")\n",
    "    # closest_points = closest_points.sort_values(by='AVSTAND_FAS') #### ÄNDRAT 2025-01-14\n",
    "    closest_points = closest_points.sort_values(by='AVST_F')\n",
    "    closest_points = closest_points.groupby('polygon_ID')\n",
    "\n",
    "    # Sorting out the closest point for each group.\n",
    "    all_closest_points_lst = []\n",
    "    for spt in closest_points:\n",
    "        for i in spt:\n",
    "            if type(i) is not int:\n",
    "                all_closest_points_lst.append(i.iloc[0])\n",
    "\n",
    "    # Cutting the polygons.\n",
    "    _yellow_RBX = clip_polygons(yellow_polygons, orange_polygons)\n",
    "    _orange_RBX = clip_polygons(orange_polygons, red_polygons)\n",
    "    _red_RBX = red_polygons\n",
    "\n",
    "    # Adding values to polygons from points.\n",
    "    # Returning polygons and all points in groups.\n",
    "    yellow_RBX_all = get_attributes_from_points(\n",
    "        _yellow_RBX, yellow_points)\n",
    "    orange_RBX_all = get_attributes_from_points(\n",
    "        _orange_RBX, orange_points)\n",
    "    red_RBX_all = get_attributes_from_points(_red_RBX, red_points)\n",
    "\n",
    "    # Sorting relevant data from get_attributes_from_point.\n",
    "    if len(yellow_RBX_all[:-1]) > 0:\n",
    "        yellow_RBX = yellow_RBX_all[:-1][0]\n",
    "    else:\n",
    "        yellow_RBX = []\n",
    "    if len(orange_RBX_all[:-1]) > 0:\n",
    "        orange_RBX = orange_RBX_all[:-1][0]\n",
    "    else:\n",
    "        orange_RBX = []\n",
    "    if len(red_RBX_all[:-1]) > 0:\n",
    "        red_RBX = red_RBX_all[:-1][0]\n",
    "    else:\n",
    "        red_RBX = []\n",
    "\n",
    "    RBX_all_lines[\"yellow\"].append(yellow_RBX)\n",
    "    RBX_all_lines[\"orange\"].append(orange_RBX)\n",
    "    RBX_all_lines[\"red\"].append(red_RBX)\n",
    "\n",
    "    # Placing \"KLASS_TEMP\" and \"Area\" values for polygons\n",
    "    all_RBX_list = []\n",
    "    for cnt, gdf in enumerate([yellow_RBX, orange_RBX, red_RBX]):\n",
    "        if len(gdf) > 0:\n",
    "            gdf['KLASS_TEMP'] = cnt+1\n",
    "            gdf['area'] = gdf.geometry.area\n",
    "            all_RBX_list.append(gdf)\n",
    "\n",
    "    # for each color, calculate RBX_area and number of clusters,\n",
    "    # and append to summary.\n",
    "    yellow_area = calculate_RBX_area(yellow_RBX)\n",
    "    orange_area = calculate_RBX_area(orange_RBX)\n",
    "    red_area = calculate_RBX_area(red_RBX)\n",
    "\n",
    "    nr_yellow = len(yellow_RBX)\n",
    "    nr_orange = len(orange_RBX)\n",
    "    nr_red = len(red_RBX)\n",
    "\n",
    "    area_summary.append([LG, line, littera, yellow_area,\n",
    "                        orange_area, red_area, nr_yellow, nr_orange, nr_red])\n",
    "\n",
    "    # Creating Geodataframe out of a list\n",
    "    all_RBX = gpd.GeoDataFrame(\n",
    "        pd.concat(all_RBX_list, ignore_index=True), crs=\"epsg:3006\")\n",
    "\n",
    "    ###################################### 2024-12-18: ORDNA FÄLT HÄR NEDANFÖR? ####################################\n",
    "    all_RBX[\"LG\"] = all_RBX[\"LG\"]\n",
    "    all_RBX.drop(\n",
    "        [\"area\", \"LG\", \"littera\"],  # , \"Shape_Length\", \"Shape_Area\"\n",
    "        axis=1,\n",
    "        inplace=True)\n",
    "\n",
    "    # Rounding up values for heights and distances.\n",
    "    all_RBX = round_values(all_RBX)\n",
    "    all_RBX_out = sort_columns(all_RBX)\n",
    "    all_RBX_out.to_file(os.path.join(\n",
    "        RBX_shape_folder, f\"{LG}_{line}_RBX.shp\"), crs=\"epsg:3006\")\n",
    "\n",
    "    # Handling all the closest points.\n",
    "    # Adding KLASS_TEMP values and rounding values up.\n",
    "    # Creating a dataframe and writing it to a .shp-file.\n",
    "    all_closest_points = gpd.GeoDataFrame(\n",
    "        all_closest_points_lst, crs=\"epsg:3006\").reset_index()\n",
    "    # Creaing default value and column for \"KLASS_TEMP\"\n",
    "    all_closest_points[\"KLASS_TEMP\"] = int(0)\n",
    "    # Using the \"set_class\" function for setting relevant \"KLASS_TEMP\" value\n",
    "    # for all closest points.\n",
    "    if len(all_closest_points) > 0:\n",
    "        all_closest_points = set_class(\n",
    "            all_closest_points, voltage, LG, littera, \"yellow\", 1)\n",
    "        all_closest_points = set_class(\n",
    "            all_closest_points, voltage, LG, littera, \"orange\", 2)\n",
    "        all_closest_points = set_class(\n",
    "            all_closest_points, voltage, LG, littera, \"red\", 3)\n",
    "    # Cleaning up GeoDataFrame from information that is not relevant.\n",
    "    all_closest_points.drop(\n",
    "        [\"index\", \"index_right\", \"polygon_ID\", \"LG\", \"littera\"],\n",
    "        axis=1,\n",
    "        inplace=True)\n",
    "    # Rounding up values for relevant columns.\n",
    "    all_closest_points = round_values(all_closest_points)\n",
    "    # Sorting columns for consistency.\n",
    "    all_closest_points_out = sort_columns(all_closest_points)\n",
    "    all_closest_points_out.to_file(os.path.join(\n",
    "        RBX_shape_folder, f\"{LG}_{line}_closest_points.shp\"), crs=\"epsg:3006\")\n",
    "\n",
    "    # Handling all the clean RBX points.\n",
    "    points = round_values(points)\n",
    "    points_out = sort_columns(points)\n",
    "    # points[\"LG\"] = points[\"LG\"].convert_dtypes('int64')\n",
    "    points_out.to_file(os.path.join(\n",
    "        RBX_shape_folder, f\"{LG}_{line}_all_points.shp\"), crs=\"epsg:3006\")\n",
    "\n",
    "# %% RUN\n",
    "# RUN\n",
    "# In RBX_distances below, yellow distance is set to 0.1 m higher than in the macro.\n",
    "# arcpy NEAR_3D and TerraScan calculations can differ slightly, so that points\n",
    "# with a distance to wire < 4.0 m according to TerraScan are further than 4.0 m\n",
    "# from wire according to arcpy. This script must include also these points.\n",
    "# 0.1 m is chosen because it's an easy number - the real differences won't be that big.\n",
    "RBX_distances = {220: {\"red\": 1.6, \"orange\": 3, \"yellow\": 4.1},\n",
    "                 300: {\"red\": 1.6, \"orange\": 3, \"yellow\": 4.1},\n",
    "                 400: {\"red\": 2.7, \"orange\": 4.3, \"yellow\": 5.6},\n",
    "                 500: {\"red\": 2.7, \"orange\": 4.3, \"yellow\": 5.6}}\n",
    "\n",
    "layerlist = fiona.listlayers(working_gdb)\n",
    "RBX_gdb_layers = [layer for layer in fiona.listlayers(\n",
    "    working_gdb) if \"RBX_clean\" in layer]\n",
    "\n",
    "# Dictionary for storing <color>_RBX geodataframes from all lines\n",
    "RBX_all_lines = {\"yellow\": [], \"orange\": [], \"red\": []}\n",
    "RBX_points_all_lines = {\"yellow\": [], \"orange\": [], \"red\": []}\n",
    "area_summary = []\n",
    "\n",
    "\n",
    "powerlines_df = pd.read_csv(powerline_list, sep=\"\\t\", header=0)\n",
    "\n",
    "powerlines_df.apply(RBX_polys_stats, axis=1)\n",
    "\n",
    "# Compute summary statistics per LG (area in square meters of yellow, orange and red RBX)\n",
    "header = ['LG', 'ledning', 'littera', 'gul', 'orange',\n",
    "          'röd', 'antal gula', 'antal orange', 'antal röda']\n",
    "df_area_summary = pd.DataFrame(area_summary, columns=header)\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff09f17",
   "metadata": {},
   "source": [
    "# Put RBX shape polygons in gdb\n",
    "\n",
    "Skriver över geometrier från shapefiler till geodatabaser. <br>\n",
    "Polygoner, all_points och closest_points hämtas från shapefiler och skrivs till geodatabasen, <br>\n",
    "feature datasets\n",
    "    * RBX_polygons\n",
    "    * RBX_closest_points\n",
    "    * RBX_all_points\n",
    "Den tar alla filer i mappen, så om även de gamla ligger i samma mapp kommer dessa att köras igen, vilket tar onödig tid. Dessutom måste de då plockas bort efteråt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "761af70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kopierade C:/SVK_2024/pythonkörningar\\RBX_shp_250128\\LG022_1_all_points.shp till C:/SVK_2024/pythonkörningar\\working_250128.gdb\\RBX_all_points som LG022_1_all_points\n",
      "Kopierade C:/SVK_2024/pythonkörningar\\RBX_shp_250128\\LG022_2_all_points.shp till C:/SVK_2024/pythonkörningar\\working_250128.gdb\\RBX_all_points som LG022_2_all_points\n",
      "Kopierade C:/SVK_2024/pythonkörningar\\RBX_shp_250128\\LG022_1_closest_points.shp till C:/SVK_2024/pythonkörningar\\working_250128.gdb\\RBX_closest_points som LG022_1_closest_points\n",
      "Kopierade C:/SVK_2024/pythonkörningar\\RBX_shp_250128\\LG022_2_closest_points.shp till C:/SVK_2024/pythonkörningar\\working_250128.gdb\\RBX_closest_points som LG022_2_closest_points\n",
      "Kopierade C:/SVK_2024/pythonkörningar\\RBX_shp_250128\\LG022_1_RBX.shp till C:/SVK_2024/pythonkörningar\\working_250128.gdb\\RBX_polygons som LG022_1_RBX\n",
      "Kopierade C:/SVK_2024/pythonkörningar\\RBX_shp_250128\\LG022_2_RBX.shp till C:/SVK_2024/pythonkörningar\\working_250128.gdb\\RBX_polygons som LG022_2_RBX\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "\n",
    "# Paths to feature classes\n",
    "RBX_polygons_fd = os.path.join(working_gdb,\"RBX_polygons\")                                                                                            # kolla även det ör som gäller vid utleverans om det är så att databasfilen ska kopieras över till utleverans\n",
    "RBX_closest_points_fd = os.path.join(working_gdb,\"RBX_closest_points\")\n",
    "RBX_all_points_fd = os.path.join(working_gdb,\"RBX_all_points\")\n",
    "\n",
    "# Path to shapefile folder\n",
    "#shp_folder = os.path.join(prj_dir, \"RBX_polygons\")\n",
    "\n",
    "\n",
    "# all_points\n",
    "shp_files = [os.path.join(RBX_shape_folder, f) for f in os.listdir(RBX_shape_folder) if f.endswith(\"_all_points.shp\")]\n",
    "\n",
    "# Loopa över listan och kopiera varje shapefil till geodatabasen\n",
    "for shp_path in shp_files:\n",
    "    # Skapa ett namn för featuren i geodatabasen (utan filändelse)\n",
    "    feature_name = os.path.splitext(os.path.basename(shp_path))[0]\n",
    "    \n",
    "    # Kopiera shapefilen till geodatabasen\n",
    "    arcpy.conversion.FeatureClassToFeatureClass(shp_path, RBX_all_points_fd, feature_name)\n",
    "    print(f\"Kopierade {shp_path} till {RBX_all_points_fd} som {feature_name}\")\n",
    "\n",
    "\n",
    "# closest_points\n",
    "shp_files = [os.path.join(RBX_shape_folder, f) for f in os.listdir(RBX_shape_folder) if f.endswith(\"_closest_points.shp\")]\n",
    "\n",
    "# Loopa över listan och kopiera varje shapefil till geodatabasen\n",
    "for shp_path in shp_files:\n",
    "    # Skapa ett namn för featuren i geodatabasen (utan filändelse)\n",
    "    feature_name = os.path.splitext(os.path.basename(shp_path))[0]\n",
    "    \n",
    "    # Kopiera shapefilen till geodatabasen\n",
    "    arcpy.conversion.FeatureClassToFeatureClass(shp_path, RBX_closest_points_fd, feature_name)\n",
    "    print(f\"Kopierade {shp_path} till {RBX_closest_points_fd} som {feature_name}\")\n",
    "    \n",
    "\n",
    "# polygons\n",
    "shp_files = [os.path.join(RBX_shape_folder, f) for f in os.listdir(RBX_shape_folder) if f.endswith(\"_RBX.shp\")]\n",
    "\n",
    "# Loopa över listan och kopiera varje shapefil till geodatabasen\n",
    "for shp_path in shp_files:\n",
    "    # Skapa ett namn för featuren i geodatabasen (utan filändelse)\n",
    "    feature_name = os.path.splitext(os.path.basename(shp_path))[0]\n",
    "    \n",
    "    # Kopiera shapefilen till geodatabasen\n",
    "    arcpy.conversion.FeatureClassToFeatureClass(shp_path, RBX_polygons_fd, feature_name)\n",
    "    print(f\"Kopierade {shp_path} till {RBX_polygons_fd} som {feature_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36053425",
   "metadata": {},
   "source": [
    "# Tar jättelång tid, borde gå att förbättra? Få fälten rätt direkt i nåt tidigare steg? Eller gör när alla featureklasser slagits ihop, om littera är fixat innan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "438f6aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixar fält för LG022_1, skannad 2024-08-06\n",
      "C:/SVK_2024/pythonkörningar\\working_250128.gdb\\RBX_polygons\\LG022_1_RBX\n",
      "    - polygoner fixade\n",
      "Skriptet är klart! Det tog 286.16 sekunder.\n",
      "    - closest_points fixade\n",
      "    - all_points fixade\n",
      "Fixar fält för LG022_2, skannad 2024-08-06\n",
      "C:/SVK_2024/pythonkörningar\\working_250128.gdb\\RBX_polygons\\LG022_2_RBX\n",
      "    - polygoner fixade\n",
      "Skriptet är klart! Det tog 281.62 sekunder.\n",
      "    - closest_points fixade\n",
      "    - all_points fixade\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcpy, os, glob, shutil, datetime, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import time\n",
    "\n",
    "# Paths to feature datasets\n",
    "RBX_polygons_fd = os.path.join(working_gdb,\"RBX_polygons\")       # kolla även det ör som gäller vid utleverans om det är så att databasfilen ska kopieras över till utleverans\n",
    "RBX_closest_points_fd = os.path.join(working_gdb,\"RBX_closest_points\")\n",
    "RBX_all_points_fd = os.path.join(working_gdb,\"RBX_all_points\")\n",
    "\n",
    "urspr = \"SWECO\"\n",
    "ins_met = 20\n",
    "matosak_plan = 1000\n",
    "matosak_hojd = 1000\n",
    "lev_dat = str(date.today())\n",
    "\n",
    "\n",
    "def fix_fields(powerline):\n",
    "    LG = powerline[\"LG\"]\n",
    "    line = powerline[\"line\"]\n",
    "    littera = powerline[\"Littera\"]\n",
    "    LG_code = cvd_LEDNINGSGATA[LG]\n",
    "    LG_date = cvd_DATE[f\"{LG}_{line}\"]\n",
    "    print(f\"Fixar fält för {LG}_{line}, skannad {LG_date}\")\n",
    "\n",
    "        \n",
    "    arcpy.env.overwriteOutput = True\n",
    "    RBX_polygons_fc = f\"{LG}_{line}_RBX\"\n",
    "    RBX_closest_points_fc = f\"{LG}_{line}_closest_points\"\n",
    "    RBX_all_points_fc = f\"{LG}_{line}_all_points\"\n",
    "    \n",
    "    print(os.path.join(RBX_polygons_fd, RBX_polygons_fc))\n",
    "    if arcpy.Exists(os.path.join(RBX_polygons_fd, RBX_polygons_fc)):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        # Polygoner\n",
    "        arcpy.env.workspace = RBX_polygons_fd\n",
    "        arcpy.management.AddField(RBX_polygons_fc, \"LITTERA\", \"TEXT\", field_length=255, field_alias=\"Littera\")\n",
    "        arcpy.management.CalculateField(RBX_polygons_fc, \"LITTERA\", \"\".join((\"'\",littera,\"'\")))\n",
    "        arcpy.management.AddField(RBX_polygons_fc, \"LEDNINGSGATA\", \"LONG\", field_alias=\"Ledningsgata\")\n",
    "        arcpy.management.CalculateField(RBX_polygons_fc, \"LEDNINGSGATA\", int(LG_code))\n",
    "        arcpy.management.AddField(RBX_polygons_fc, \"RGDTM\", \"DATE\", field_alias=\"Registreringsdatum\")\n",
    "        arcpy.management.CalculateField(RBX_polygons_fc, \"RGDTM\", \"\".join((\"'\",LG_date,\"'\")))\n",
    "        arcpy.management.AddField(RBX_polygons_fc, \"Ursprung\", \"TEXT\")\n",
    "        arcpy.management.CalculateField(RBX_polygons_fc, \"Ursprung\", \"\".join((\"'\", urspr, \"'\")))\n",
    "        arcpy.management.AddField(RBX_polygons_fc, \"Ursprung_Datum\", \"DATE\")\n",
    "        arcpy.management.CalculateField(RBX_polygons_fc, \"Ursprung_Datum\", \"\".join((\"'\", lev_dat, \"'\")))\n",
    "        arcpy.management.AddField(RBX_polygons_fc, \"Insamlingsmetod\", \"LONG\", field_alias=\"Inventeringsmetod\")\n",
    "        arcpy.management.CalculateField(RBX_polygons_fc, \"Insamlingsmetod\", int(ins_met))\n",
    "        arcpy.management.AddField(RBX_polygons_fc, \"Matosakerhet_Plan\", \"LONG\", field_alias=\"Mätosäkerhet i plan\")\n",
    "        arcpy.management.CalculateField(RBX_polygons_fc, \"Matosakerhet_Plan\", int(matosak_plan))\n",
    "        arcpy.management.AddField(RBX_polygons_fc, \"Matosakerhet_Hojd\", \"LONG\", field_alias=\"Mätosäkerhet i höjd\")\n",
    "        arcpy.management.CalculateField(RBX_polygons_fc, \"Matosakerhet_Hojd\", int(matosak_hojd))\n",
    "        arcpy.management.AddField(RBX_polygons_fc, \"KLASS\", \"SHORT\", field_alias=\"Klass\")        \n",
    "        arcpy.management.CalculateField(RBX_polygons_fc, \"KLASS\", \"!KLASS_TEMP!\", \"PYTHON3\")\n",
    "        arcpy.management.DeleteField(RBX_polygons_fc, \"KLASS_TEMP\")\n",
    "        arcpy.management.AlterField(RBX_polygons_fc, \"AVST_F\", \"AVSTAND_FAS\", new_field_alias=\"Avstånd till fas [m]\")\n",
    "        arcpy.management.AlterField(RBX_polygons_fc, \"AVST_H\", \"AVSTAND_HORISONTELLT\", new_field_alias=\"Horisontellt avstånd till fas [m]\")\n",
    "        arcpy.management.AlterField(RBX_polygons_fc, \"dz\", \"DELTA_HOJD\", new_field_alias=\"Trädhöjd [m]\")\n",
    "        \n",
    "        arcpy.management.AssignDomainToField(RBX_polygons_fc, \"LEDNINGSGATA\", \"cvd_LEDNINGSGATA\")\n",
    "        arcpy.management.AssignDomainToField(RBX_polygons_fc, \"LITTERA\", \"cvd_LITTERA_LEDNING\")\n",
    "        arcpy.management.AssignDomainToField(RBX_polygons_fc, \"Matosakerhet_Hojd\", \"cvd_MATOSAKERHET\")\n",
    "        arcpy.management.AssignDomainToField(RBX_polygons_fc, \"Matosakerhet_Plan\", \"cvd_MATOSAKERHET\")\n",
    "        arcpy.management.AssignDomainToField(RBX_polygons_fc, \"Insamlingsmetod\", \"cvd_INMATNINGSMETOD\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(\"    - polygoner fixade\")\n",
    "        \n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        print(f\"Skriptet är klart! Det tog {elapsed_time:.2f} sekunder.\")\n",
    "        \n",
    "        # Closest points\n",
    "        arcpy.env.workspace = RBX_closest_points_fd\n",
    "\n",
    "        arcpy.management.AddField(RBX_closest_points_fc, \"LITTERA\", \"TEXT\", field_length=255, field_alias=\"Littera\")\n",
    "        arcpy.management.CalculateField(RBX_closest_points_fc, \"LITTERA\", \"\".join((\"'\",littera,\"'\")))\n",
    "        arcpy.management.AddField(RBX_closest_points_fc, \"LEDNINGSGATA\", \"LONG\", field_alias=\"Ledningsgata\")\n",
    "        arcpy.management.CalculateField(RBX_closest_points_fc, \"LEDNINGSGATA\", int(LG_code))\n",
    "        arcpy.management.AddField(RBX_closest_points_fc, \"RGDTM\", \"DATE\", field_alias=\"Registreringsdatum\")\n",
    "        arcpy.management.CalculateField(RBX_closest_points_fc, \"RGDTM\", \"\".join((\"'\",LG_date,\"'\")))\n",
    "        arcpy.management.AddField(RBX_closest_points_fc, \"Ursprung\", \"TEXT\")\n",
    "        arcpy.management.CalculateField(RBX_closest_points_fc, \"Ursprung\", \"\".join((\"'\", urspr, \"'\")))\n",
    "        arcpy.management.AddField(RBX_closest_points_fc, \"Ursprung_Datum\", \"DATE\")\n",
    "        arcpy.management.CalculateField(RBX_closest_points_fc, \"Ursprung_Datum\", \"\".join((\"'\", lev_dat, \"'\")))\n",
    "        arcpy.management.AddField(RBX_closest_points_fc, \"Insamlingsmetod\", \"LONG\", field_alias=\"Inventeringsmetod\")\n",
    "        arcpy.management.CalculateField(RBX_closest_points_fc, \"Insamlingsmetod\", int(ins_met))\n",
    "        arcpy.management.AddField(RBX_closest_points_fc, \"Matosakerhet_Plan\", \"LONG\", field_alias=\"Mätosäkerhet i plan\")\n",
    "        arcpy.management.CalculateField(RBX_closest_points_fc, \"Matosakerhet_Plan\", int(matosak_plan))\n",
    "        arcpy.management.AddField(RBX_closest_points_fc, \"Matosakerhet_Hojd\", \"LONG\", field_alias=\"Mätosäkerhet i höjd\")\n",
    "        arcpy.management.CalculateField(RBX_closest_points_fc, \"Matosakerhet_Hojd\", int(matosak_hojd))\n",
    "        arcpy.management.AddField(RBX_closest_points_fc, \"KLASS\", \"SHORT\", field_alias=\"Klass\")        \n",
    "        arcpy.management.CalculateField(RBX_closest_points_fc, \"KLASS\", \"!KLASS_TEMP!\", \"PYTHON3\")\n",
    "        arcpy.management.DeleteField(RBX_closest_points_fc, \"KLASS_TEMP\")\n",
    "        arcpy.management.AlterField(RBX_closest_points_fc, \"AVST_F\", \"AVSTAND_FAS\", new_field_alias=\"Avstånd till fas [m]\")\n",
    "        arcpy.management.AlterField(RBX_closest_points_fc, \"AVST_H\", \"AVSTAND_HORISONTELLT\", new_field_alias=\"Horisontellt avstånd till fas [m]\")\n",
    "        arcpy.management.AlterField(RBX_closest_points_fc, \"dz\", \"DELTA_HOJD\", new_field_alias=\"Trädhöjd [m]\")\n",
    "        \n",
    "        arcpy.management.AssignDomainToField(RBX_closest_points_fc, \"LEDNINGSGATA\", \"cvd_LEDNINGSGATA\")\n",
    "        arcpy.management.AssignDomainToField(RBX_closest_points_fc, \"LITTERA\", \"cvd_LITTERA_LEDNING\")\n",
    "        arcpy.management.AssignDomainToField(RBX_closest_points_fc, \"Matosakerhet_Hojd\", \"cvd_MATOSAKERHET\")\n",
    "        arcpy.management.AssignDomainToField(RBX_closest_points_fc, \"Matosakerhet_Plan\", \"cvd_MATOSAKERHET\")\n",
    "        arcpy.management.AssignDomainToField(RBX_closest_points_fc, \"Insamlingsmetod\", \"cvd_INMATNINGSMETOD\")\n",
    "        \n",
    "        print(\"    - closest_points fixade\")\n",
    "\n",
    "        \n",
    "        # All points\n",
    "        arcpy.env.workspace = RBX_all_points_fd\n",
    "\n",
    "        arcpy.management.AddField(RBX_all_points_fc, \"LITTERA\", \"TEXT\", field_length=255, field_alias=\"Littera\")\n",
    "        arcpy.management.CalculateField(RBX_all_points_fc, \"LITTERA\", \"\".join((\"'\",littera,\"'\")))\n",
    "        arcpy.management.AddField(RBX_all_points_fc, \"LEDNINGSGATA\", \"LONG\", field_alias=\"Ledningsgata\")\n",
    "        arcpy.management.CalculateField(RBX_all_points_fc, \"LEDNINGSGATA\", int(LG_code))\n",
    "        arcpy.management.AddField(RBX_all_points_fc, \"RGDTM\", \"DATE\", field_alias=\"Registreringsdatum\")\n",
    "        arcpy.management.CalculateField(RBX_all_points_fc, \"RGDTM\", \"\".join((\"'\",LG_date,\"'\")))\n",
    "        arcpy.management.AddField(RBX_all_points_fc, \"Ursprung\", \"TEXT\")\n",
    "        arcpy.management.CalculateField(RBX_all_points_fc, \"Ursprung\", \"\".join((\"'\", urspr, \"'\")))\n",
    "        arcpy.management.AddField(RBX_all_points_fc, \"Ursprung_Datum\", \"DATE\")\n",
    "        arcpy.management.CalculateField(RBX_all_points_fc, \"Ursprung_Datum\", \"\".join((\"'\", lev_dat, \"'\")))\n",
    "        arcpy.management.AddField(RBX_all_points_fc, \"Insamlingsmetod\", \"LONG\", field_alias=\"Inventeringsmetod\")\n",
    "        arcpy.management.CalculateField(RBX_all_points_fc, \"Insamlingsmetod\", int(ins_met))\n",
    "        arcpy.management.AddField(RBX_all_points_fc, \"Matosakerhet_Plan\", \"LONG\", field_alias=\"Mätosäkerhet i plan\")\n",
    "        arcpy.management.CalculateField(RBX_all_points_fc, \"Matosakerhet_Plan\", int(matosak_plan))\n",
    "        arcpy.management.AddField(RBX_all_points_fc, \"Matosakerhet_Hojd\", \"LONG\", field_alias=\"Mätosäkerhet i höjd\")\n",
    "        arcpy.management.CalculateField(RBX_all_points_fc, \"Matosakerhet_Hojd\", int(matosak_hojd))\n",
    "        arcpy.management.AddField(RBX_all_points_fc, \"KLASS\", \"SHORT\", field_alias=\"Klass\")        \n",
    "        arcpy.management.CalculateField(RBX_all_points_fc, \"KLASS\", \"!KLASS_TEMP!\", \"PYTHON3\")\n",
    "        arcpy.management.DeleteField(RBX_all_points_fc, \"KLASS_TEMP\")\n",
    "        arcpy.management.AlterField(RBX_all_points_fc, \"AVST_F\", \"AVSTAND_FAS\", new_field_alias=\"Avstånd till fas [m]\")\n",
    "        arcpy.management.AlterField(RBX_all_points_fc, \"AVST_H\", \"AVSTAND_HORISONTELLT\", new_field_alias=\"Horisontellt avstånd till fas [m]\")\n",
    "        arcpy.management.AlterField(RBX_all_points_fc, \"dz\", \"DELTA_HOJD\", new_field_alias=\"Trädhöjd [m]\")\n",
    "        \n",
    "        arcpy.management.AssignDomainToField(RBX_all_points_fc, \"LEDNINGSGATA\", \"cvd_LEDNINGSGATA\")\n",
    "        arcpy.management.AssignDomainToField(RBX_all_points_fc, \"LITTERA\", \"cvd_LITTERA_LEDNING\")\n",
    "        arcpy.management.AssignDomainToField(RBX_all_points_fc, \"Matosakerhet_Hojd\", \"cvd_MATOSAKERHET\")\n",
    "        arcpy.management.AssignDomainToField(RBX_all_points_fc, \"Matosakerhet_Plan\", \"cvd_MATOSAKERHET\")\n",
    "        arcpy.management.AssignDomainToField(RBX_all_points_fc, \"Insamlingsmetod\", \"cvd_INMATNINGSMETOD\")\n",
    "        \n",
    "        print(\"    - all_points fixade\")\n",
    "    \n",
    "powerlines_df = pd.read_csv(powerline_list, sep=\"\\t\", header=0)\n",
    "df_cvd_LEDNINGSGATA = pd.read_csv(cvd_LEDNINGSGATA_path, sep=\"\\t\", header=0)\n",
    "df_cvd_DATE = pd.read_csv(scandate_file, sep=\"\\t\", header=0)\n",
    "cvd_LEDNINGSGATA = {df_cvd_LEDNINGSGATA.Description[i]: df_cvd_LEDNINGSGATA.Code[i] for i in range(len(df_cvd_LEDNINGSGATA))}\n",
    "cvd_DATE = {f\"{row['LG']}_{int(row['line'])}\": row['skanningsdatum'] for _, row in df_cvd_DATE.iterrows()}\n",
    "\n",
    "powerlines_df.apply(fix_fields, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06bf94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cvd_DATE = pd.read_csv(scandate_file, sep=\"\\t\", header=0)\n",
    "cvd_DATE = {f\"{row['LG']}_{int(row['line'])}\": row['skanningsdatum'] for _, row in df_cvd_DATE.iterrows()}\n",
    "print(df_cvd_DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5a945d",
   "metadata": {},
   "source": [
    "# Komplettering lagernamn\n",
    "Eftersom shapefiler inte kan fältnamn längre än 10 symboler, kompletter detta skript lagernamnen enligt<br>\n",
    "SVKs manual.<br>\n",
    "Ändrar även namn på dz till DELTA_HOJD, vilken kan bytas ut i det externa skriptet när tid ges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98a86289",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Altering fields for LG026_1\n",
      "Altering field for LG026_1\n",
      "Altering fields for LG026_1\n",
      "Altering field for LG026_1\n",
      "Altering fields for LG026_1\n",
      "Altering field for LG026_1\n",
      "Altering fields for LG026_2\n",
      "Altering field for LG026_2\n",
      "Altering fields for LG026_2\n",
      "Altering field for LG026_2\n",
      "Altering fields for LG026_2\n",
      "Altering field for LG026_2\n",
      "No RBX for LG026_3\n",
      "Altering fields for LG026_4\n",
      "Altering field for LG026_4\n",
      "Altering fields for LG026_4\n",
      "Altering field for LG026_4\n",
      "Altering fields for LG026_4\n",
      "Altering field for LG026_4\n",
      "Altering fields for LG026_6\n",
      "Altering field for LG026_6\n",
      "Altering fields for LG026_6\n",
      "Altering field for LG026_6\n",
      "Altering fields for LG026_6\n",
      "Altering field for LG026_6\n",
      "No RBX for LG040_1\n",
      "No RBX for LG040_2\n",
      "No RBX for LG040_3\n",
      "No RBX for LG040_4\n",
      "No RBX for LG040_5\n",
      "No RBX for LG040_6\n",
      "No RBX for LG040_7\n",
      "No RBX for LG040_8\n",
      "Altering fields for LG041_1\n",
      "Altering field for LG041_1\n",
      "Altering fields for LG041_1\n",
      "Altering field for LG041_1\n",
      "Altering fields for LG041_1\n",
      "Altering field for LG041_1\n",
      "Altering fields for LG041_2\n",
      "Altering field for LG041_2\n",
      "Altering fields for LG041_2\n",
      "Altering field for LG041_2\n",
      "Altering fields for LG041_2\n",
      "Altering field for LG041_2\n",
      "Altering fields for LG041_3\n",
      "Altering field for LG041_3\n",
      "Altering fields for LG041_3\n",
      "Altering field for LG041_3\n",
      "Altering fields for LG041_3\n",
      "Altering field for LG041_3\n",
      "Altering fields for LG041_4\n",
      "Altering field for LG041_4\n",
      "Altering fields for LG041_4\n",
      "Altering field for LG041_4\n",
      "Altering fields for LG041_4\n",
      "Altering field for LG041_4\n",
      "Altering fields for LG041_5\n",
      "Altering field for LG041_5\n",
      "Altering fields for LG041_5\n",
      "Altering field for LG041_5\n",
      "Altering fields for LG041_5\n",
      "Altering field for LG041_5\n",
      "No RBX for LG042_1\n",
      "Altering fields for LG051_1\n",
      "Altering field for LG051_1\n",
      "Altering fields for LG051_1\n",
      "Altering field for LG051_1\n",
      "Altering fields for LG051_1\n",
      "Altering field for LG051_1\n",
      "No RBX for LG051_2\n",
      "Altering fields for LG051_3\n",
      "Altering field for LG051_3\n",
      "Altering fields for LG051_3\n",
      "Altering field for LG051_3\n",
      "Altering fields for LG051_3\n",
      "Altering field for LG051_3\n",
      "No RBX for LG051_4\n",
      "No RBX for LG051_5\n",
      "Altering fields for LG052_1\n",
      "Altering field for LG052_1\n",
      "Altering fields for LG052_1\n",
      "Altering field for LG052_1\n",
      "Altering fields for LG052_1\n",
      "Altering field for LG052_1\n",
      "Altering fields for LG052_2\n",
      "Altering field for LG052_2\n",
      "Altering fields for LG052_2\n",
      "Altering field for LG052_2\n",
      "Altering fields for LG052_2\n",
      "Altering field for LG052_2\n",
      "No RBX for LG052_3\n",
      "Altering fields for LG057_1\n",
      "Altering field for LG057_1\n",
      "Altering fields for LG057_1\n",
      "Altering field for LG057_1\n",
      "Altering fields for LG057_1\n",
      "Altering field for LG057_1\n",
      "No RBX for LG057_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "5     None\n",
       "6     None\n",
       "7     None\n",
       "8     None\n",
       "9     None\n",
       "10    None\n",
       "11    None\n",
       "12    None\n",
       "13    None\n",
       "14    None\n",
       "15    None\n",
       "16    None\n",
       "17    None\n",
       "18    None\n",
       "19    None\n",
       "20    None\n",
       "21    None\n",
       "22    None\n",
       "23    None\n",
       "24    None\n",
       "25    None\n",
       "26    None\n",
       "27    None\n",
       "28    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import arcpy, os, glob, SVK, shutil\n",
    "#from pathlib import Path\n",
    "#import pandas as pd\n",
    "#\n",
    "#RBX_shp_dir = os.path.join(prj_dir,\"RBX_polygons\")\n",
    "#RBX_polygons_fd = os.path.join(gdb,\"RBX_polygons\")                                                                                            \n",
    "#RBX_closest_points_fd = os.path.join(gdb,\"RBX_closest_points\")\n",
    "#RBX_all_points_fd = os.path.join(gdb,\"RBX_all_points\")\n",
    "#\n",
    "#def shp2gdb(powerline):\n",
    "#    LG = powerline[0]\n",
    "#    line = powerline[1]\n",
    "#    \n",
    "#    RBX_polygons_shp_path = os.path.join(RBX_shp_dir,f\"{LG}_{line}_RBX.shp\")\n",
    "#    RBX_closest_points_shp_path = os.path.join(RBX_shp_dir,f\"{LG}_{line}_closest_points.shp\")\n",
    "#    RBX_all_points_shp_path = os.path.join(RBX_shp_dir,f\"{LG}_{line}_all_points.shp\")\n",
    "#    RBX_polygons_fc = f\"RBX_polygon_{LG}_{line}\"\n",
    "#    RBX_closest_points_fc = f\"RBX_closest_points_{LG}_{line}\"\n",
    "#    RBX_all_points_fc = f\"RBX_all_points_{LG}_{line}\"\n",
    "#    ch_fd_lst = [RBX_polygons_fd, RBX_closest_points_fd, RBX_all_points_fd]\n",
    "#    ch_fc_lst = [RBX_polygons_fc, RBX_closest_points_fc,RBX_all_points_fc]\n",
    "#    \n",
    "#    if os.path.exists(RBX_polygons_shp_path):\n",
    "#        for fd, fc in zip(ch_fd_lst, ch_fc_lst):\n",
    "#            print(f\"Altering fields for {LG}_{line}\")\n",
    "#            path_joined = os.path.join(fd, fc)\n",
    "#            field_names = [f.name for f in arcpy.ListFields(path_joined)]\n",
    "#            if \"AVSTAND_HO\" in field_names: \n",
    "#                print(f\"Altering field for {LG}_{line}\")\n",
    "#                arcpy.management.AlterField(\n",
    "#                    path_joined,\n",
    "#                    \"AVSTAND_HO\",\n",
    "#                    \"AVSTAND_HORISONTELLT\",\n",
    "#                    \"AVSTAND_HORISONTELLT\")\n",
    "#            if \"AVSTAND_FA\" in field_names:    \n",
    "#                arcpy.management.AlterField(\n",
    "#                    path_joined,\n",
    "#                    \"AVSTAND_FA\",\n",
    "#                    \"AVSTAND_FAS\",\n",
    "#                    \"AVSTAND_FAS\")\n",
    "#            if \"dz\" in field_names:    \n",
    "#                arcpy.management.AlterField(\n",
    "#                    path_joined,\n",
    "#                    \"dz\",\n",
    "#                    \"DELTA_HOJD\",\n",
    "#                    \"DELTA_HOJD\")\n",
    "#    else:\n",
    "#        print(f\"No RBX for {LG}_{line}\")\n",
    "#    \n",
    "#LGs_info = pd.read_csv(LGs_info_path, sep=\"\\t\", header=0)\n",
    "#LGs_info.apply(shp2gdb, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e494eb7",
   "metadata": {},
   "source": [
    "## Slå ihop de olika ledningarnas featureklasser till en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d94867fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "\n",
    "results_gdb = os.path.join(local_dir, f\"results_{run_ID}.gdb\")\n",
    "\n",
    "# RBX ALL POINTS\n",
    "target_fc = os.path.join(results_gdb, \"RBX_all_points\")\n",
    "# Sätt workspace till working GDB\\RBX_all_points\n",
    "arcpy.env.workspace = os.path.join(working_gdb, \"RBX_all_points\")\n",
    "# lista featureklasser att kopiera\n",
    "feature_classes = arcpy.ListFeatureClasses()\n",
    "# Gå igenom varje featureklass och append till target GDB\n",
    "for fc in feature_classes:\n",
    "    arcpy.Append_management(inputs=fc, target=target_fc, schema_type=\"NO_TEST\")\n",
    "\n",
    "# RBX CLOSEST POINTS\n",
    "target_fc = os.path.join(results_gdb, \"RBX_closest_points\")\n",
    "# Sätt workspace till working GDB\\RBX_closest_points\n",
    "arcpy.env.workspace = os.path.join(working_gdb, \"RBX_closest_points\")\n",
    "# lista featureklasser att kopiera\n",
    "feature_classes = arcpy.ListFeatureClasses()\n",
    "# Gå igenom varje featureklass och append till target GDB\n",
    "for fc in feature_classes:\n",
    "    arcpy.Append_management(inputs=fc, target=target_fc, schema_type=\"NO_TEST\")\n",
    "    \n",
    "# RBX POLYGONS\n",
    "target_fc = os.path.join(results_gdb, \"RBX_polygons\")\n",
    "# Sätt workspace till working GDB\\RBX_polygons\n",
    "arcpy.env.workspace = os.path.join(working_gdb, \"RBX_polygons\")\n",
    "# lista featureklasser att kopiera\n",
    "feature_classes = arcpy.ListFeatureClasses()\n",
    "# Gå igenom varje featureklass och append till target GDB\n",
    "for fc in feature_classes:\n",
    "    arcpy.Append_management(inputs=fc, target=target_fc, schema_type=\"NO_TEST\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60813dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  },
  "vscode": {
   "interpreter": {
    "hash": "ffbc243d4c34405bc6fb8628382980f52a7cce3449f1ef6e2be164cd66473a08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
